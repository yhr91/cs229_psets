\item \subquestionpoints{5}
Suppose we use the sigmoid function as the activation function for $h_1, h_2, h_3$ and $o$.
What is the gradient descent update to $w_{1, 2}^{[1]}$, assuming we use a learning rate of $\alpha$?
Your answer should be written in terms of $\xsi$, $o^{(i)}$, $\ysi$, and the weights.

